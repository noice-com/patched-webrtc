From e963e9c3ce173f06dd212899b68514c57b500a2b Mon Sep 17 00:00:00 2001
From: mekya <ahmetmermerkaya@gmail.com>
Date: Sat, 26 Nov 2022 15:44:59 +0300
Subject: [PATCH 1/2] Patch RTCAudioDeviceModule and Mic Permission for
 Playback

Signed-off-by: mekya <ahmetmermerkaya@gmail.com>
Signed-off-by: Antti Tapaninen <aet@aet.fi>
---
 sdk/BUILD.gn                                  |   7 +
 .../RTCAudioDeviceModule+Private.h            |  16 ++
 .../api/peerconnection/RTCAudioDeviceModule.h |  18 +++
 .../peerconnection/RTCAudioDeviceModule.mm    |  27 ++++
 .../peerconnection/RTCPeerConnectionFactory.h |   6 +
 .../RTCPeerConnectionFactory.mm               |  26 ++++
 sdk/objc/native/src/audio/audio_device_ios.h  |  11 +-
 sdk/objc/native/src/audio/audio_device_ios.mm | 147 +++++++++++++++---
 .../src/audio/audio_device_module_ios.h       |   4 +
 .../src/audio/audio_device_module_ios.mm      |   5 +
 .../src/audio/voice_processing_audio_unit.mm  | 114 +++++++++-----
 11 files changed, 314 insertions(+), 67 deletions(-)
 create mode 100644 sdk/objc/api/peerconnection/RTCAudioDeviceModule+Private.h
 create mode 100644 sdk/objc/api/peerconnection/RTCAudioDeviceModule.h
 create mode 100644 sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm

diff --git a/sdk/BUILD.gn b/sdk/BUILD.gn
index ff89b21721..b80bfaa6ca 100644
--- a/sdk/BUILD.gn
+++ b/sdk/BUILD.gn
@@ -943,6 +943,7 @@ if (is_ios || is_mac) {
       ]
       configs += [ "..:no_global_constructors" ]
       sources = [
+        "objc/api/peerconnection/RTCAudioDeviceModule.h",
         "objc/api/peerconnection/RTCAudioSource+Private.h",
         "objc/api/peerconnection/RTCAudioSource.h",
         "objc/api/peerconnection/RTCAudioSource.mm",
@@ -1114,6 +1115,10 @@ if (is_ios || is_mac) {
       ]
 
       if (is_ios) {
+        sources += [
+          "objc/api/peerconnection/RTCAudioDeviceModule+Private.h",
+          "objc/api/peerconnection/RTCAudioDeviceModule.mm",
+        ]
         deps += [ ":native_api_audio_device_module" ]
       }
     }
@@ -1308,6 +1313,7 @@ if (is_ios || is_mac) {
           "objc/helpers/RTCCameraPreviewView.h",
           "objc/helpers/RTCDispatcher.h",
           "objc/helpers/UIDevice+RTCDevice.h",
+          "objc/api/peerconnection/RTCAudioDeviceModule.h",
           "objc/api/peerconnection/RTCAudioSource.h",
           "objc/api/peerconnection/RTCAudioTrack.h",
           "objc/api/peerconnection/RTCConfiguration.h",
@@ -1422,6 +1428,7 @@ if (is_ios || is_mac) {
         output_name = "WebRTC"
 
         sources = [
+          "objc/api/peerconnection/RTCAudioDeviceModule.h",
           "objc/api/peerconnection/RTCAudioSource.h",
           "objc/api/peerconnection/RTCAudioTrack.h",
           "objc/api/peerconnection/RTCCertificate.h",
diff --git a/sdk/objc/api/peerconnection/RTCAudioDeviceModule+Private.h b/sdk/objc/api/peerconnection/RTCAudioDeviceModule+Private.h
new file mode 100644
index 0000000000..72ccd693c6
--- /dev/null
+++ b/sdk/objc/api/peerconnection/RTCAudioDeviceModule+Private.h
@@ -0,0 +1,16 @@
+#import "RTCAudioDeviceModule.h"
+
+#if defined(WEBRTC_IOS)
+#include "sdk/objc/native/src/audio/audio_device_module_ios.h"
+
+NS_ASSUME_NONNULL_BEGIN
+
+@interface RTCAudioDeviceModule ()
+
+@property(nonatomic, readonly) rtc::scoped_refptr<webrtc::ios_adm::AudioDeviceModuleIOS>
+    nativeModule;
+
+@end
+
+NS_ASSUME_NONNULL_END
+#endif
\ No newline at end of file
diff --git a/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h
new file mode 100644
index 0000000000..d8aba54508
--- /dev/null
+++ b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h
@@ -0,0 +1,18 @@
+
+#import <CoreMedia/CoreMedia.h>
+#import <Foundation/Foundation.h>
+
+#import "RTCMacros.h"
+
+NS_ASSUME_NONNULL_BEGIN
+
+RTC_OBJC_EXPORT
+
+NS_CLASS_AVAILABLE_IOS(2_0)
+@interface RTCAudioDeviceModule : NSObject
+
+- (void)deliverRecordedData:(CMSampleBufferRef)sampleBuffer;
+
+@end
+
+NS_ASSUME_NONNULL_END
\ No newline at end of file
diff --git a/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm
new file mode 100644
index 0000000000..531bac8eda
--- /dev/null
+++ b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm
@@ -0,0 +1,27 @@
+
+#include <AudioUnit/AudioUnit.h>
+
+#import "RTCAudioDeviceModule+Private.h"
+#include "rtc_base/ref_counted_object.h"
+
+@implementation RTCAudioDeviceModule {
+  rtc::scoped_refptr<webrtc::ios_adm::AudioDeviceModuleIOS> _nativeModule;
+}
+
+- (instancetype)init {
+  self = [super init];
+  _nativeModule = new rtc::RefCountedObject<webrtc::ios_adm::AudioDeviceModuleIOS>(false);
+  return self;
+}
+
+- (void)deliverRecordedData:(CMSampleBufferRef)sampleBuffer {
+  _nativeModule->OnDeliverRecordedExternalData(sampleBuffer);
+}
+
+#pragma mark - Private
+
+- (rtc::scoped_refptr<webrtc::ios_adm::AudioDeviceModuleIOS>)nativeModule {
+  return _nativeModule;
+}
+
+@end
\ No newline at end of file
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
index 5575af98c9..e3774af4a4 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.h
@@ -10,6 +10,7 @@
 
 #import <Foundation/Foundation.h>
 
+#import "RTCAudioDeviceModule.h"
 #import "RTCMacros.h"
 
 NS_ASSUME_NONNULL_BEGIN
@@ -51,6 +52,11 @@ RTC_OBJC_EXPORT
             decoderFactory:(nullable id<RTC_OBJC_TYPE(RTCVideoDecoderFactory)>)decoderFactory
                audioDevice:(nullable id<RTC_OBJC_TYPE(RTCAudioDevice)>)audioDevice;
 
+- (instancetype)initWithEncoderFactory:(nullable id<RTCVideoEncoderFactory>)encoderFactory
+                        decoderFactory:(nullable id<RTCVideoDecoderFactory>)decoderFactory
+                     audioDeviceModule:(RTCAudioDeviceModule *)audioDeviceModule
+    NS_AVAILABLE_IOS(2_0);
+
 /** Initialize an RTCAudioSource with constraints. */
 - (RTC_OBJC_TYPE(RTCAudioSource) *)audioSourceWithConstraints:
     (nullable RTC_OBJC_TYPE(RTCMediaConstraints) *)constraints;
diff --git a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
index 62b55543d4..387624dcca 100644
--- a/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
+++ b/sdk/objc/api/peerconnection/RTCPeerConnectionFactory.mm
@@ -14,6 +14,7 @@
 #import "RTCPeerConnectionFactory+Private.h"
 #import "RTCPeerConnectionFactoryOptions+Private.h"
 
+#import "RTCAudioDeviceModule+Private.h"
 #import "RTCAudioSource+Private.h"
 #import "RTCAudioTrack+Private.h"
 #import "RTCMediaConstraints+Private.h"
@@ -116,6 +117,31 @@ - (instancetype)init {
 #endif
 }
 
+#if defined(WEBRTC_IOS)
+- (instancetype)initWithEncoderFactory:(nullable id<RTCVideoEncoderFactory>)encoderFactory
+                        decoderFactory:(nullable id<RTCVideoDecoderFactory>)decoderFactory
+                     audioDeviceModule:(RTCAudioDeviceModule *)audioDeviceModule {
+#ifdef HAVE_NO_MEDIA
+  return [self initWithNoMedia];
+#else
+  std::unique_ptr<webrtc::VideoEncoderFactory> native_encoder_factory;
+  std::unique_ptr<webrtc::VideoDecoderFactory> native_decoder_factory;
+  if (encoderFactory) {
+    native_encoder_factory = webrtc::ObjCToNativeVideoEncoderFactory(encoderFactory);
+  }
+  if (decoderFactory) {
+    native_decoder_factory = webrtc::ObjCToNativeVideoDecoderFactory(decoderFactory);
+  }
+  return [self initWithNativeAudioEncoderFactory:webrtc::CreateBuiltinAudioEncoderFactory()
+                       nativeAudioDecoderFactory:webrtc::CreateBuiltinAudioDecoderFactory()
+                       nativeVideoEncoderFactory:std::move(native_encoder_factory)
+                       nativeVideoDecoderFactory:std::move(native_decoder_factory)
+                               audioDeviceModule:audioDeviceModule.nativeModule.get()
+                           audioProcessingModule:nullptr];
+#endif
+}
+#endif
+
 - (instancetype)initNative {
   if (self = [super init]) {
     _networkThread = rtc::Thread::CreateWithSocketServer();
diff --git a/sdk/objc/native/src/audio/audio_device_ios.h b/sdk/objc/native/src/audio/audio_device_ios.h
index a86acb56fe..615eec47ee 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_ios.h
@@ -11,6 +11,8 @@
 #ifndef SDK_OBJC_NATIVE_SRC_AUDIO_AUDIO_DEVICE_IOS_H_
 #define SDK_OBJC_NATIVE_SRC_AUDIO_AUDIO_DEVICE_IOS_H_
 
+#include <CoreMedia/CoreMedia.h>
+
 #include <atomic>
 #include <memory>
 
@@ -148,6 +150,8 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
   void OnCanPlayOrRecordChange(bool can_play_or_record) override;
   void OnChangedOutputVolume() override;
 
+  void OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer);
+
   // VoiceProcessingAudioUnitObserver methods.
   OSStatus OnDeliverRecordedData(AudioUnitRenderActionFlags* flags,
                                  const AudioTimeStamp* time_stamp,
@@ -212,7 +216,10 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
   const bool bypass_voice_processing_;
 
   // Native I/O audio thread checker.
-  SequenceChecker io_thread_checker_;
+  // SequenceChecker io_thread_checker_;
+
+  // Native audio I/O mutex.
+  Mutex io_mutex_;
 
   // Thread that this object is created on.
   rtc::Thread* thread_;
@@ -285,7 +292,7 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
 
   // Counts number of detected audio glitches on the playout side.
   int64_t num_detected_playout_glitches_ RTC_GUARDED_BY(thread_);
-  int64_t last_playout_time_ RTC_GUARDED_BY(io_thread_checker_);
+  int64_t last_playout_time_ RTC_GUARDED_BY(io_mutex_);
 
   // Counts number of playout callbacks per call.
   // The value is updated on the native I/O thread and later read on the
diff --git a/sdk/objc/native/src/audio/audio_device_ios.mm b/sdk/objc/native/src/audio/audio_device_ios.mm
index dd2c11bdd2..2c551922c3 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_ios.mm
@@ -8,11 +8,11 @@
  *  be found in the AUTHORS file in the root of the source tree.
  */
 
+#include "audio_device_ios.h"
 #import <AVFoundation/AVFoundation.h>
+#import <CoreMedia/CoreMedia.h>
 #import <Foundation/Foundation.h>
 
-#include "audio_device_ios.h"
-
 #include <cmath>
 
 #include "api/array_view.h"
@@ -106,7 +106,7 @@ static void LogDeviceInfo() {
       last_output_volume_change_time_(0) {
   LOGI() << "ctor" << ios::GetCurrentThreadDescription()
          << ",bypass_voice_processing=" << bypass_voice_processing_;
-  io_thread_checker_.Detach();
+  // io_thread_checker_.Detach();
   thread_ = rtc::Thread::Current();
 
   audio_session_observer_ = [[RTCNativeAudioSessionDelegateAdapter alloc] initWithObserver:this];
@@ -129,7 +129,7 @@ static void LogDeviceInfo() {
 
 AudioDeviceGeneric::InitStatus AudioDeviceIOS::Init() {
   LOGI() << "Init";
-  io_thread_checker_.Detach();
+  // io_thread_checker_.Detach();
 
   RTC_DCHECK_RUN_ON(thread_);
   if (initialized_) {
@@ -360,12 +360,71 @@ static void LogDeviceInfo() {
   thread_->PostTask(SafeTask(safety_, [this] { HandleOutputVolumeChange(); }));
 }
 
+void AudioDeviceIOS::OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer) {
+  MutexLock scoped_lock(&io_mutex_);
+
+  if (audio_unit_ && audio_unit_->GetState() != VoiceProcessingAudioUnit::kUninitialized) {
+    RTCLogError(@"External recorded data was provided while audio unit is enabled.");
+    return;
+  }
+
+  CMFormatDescriptionRef description = CMSampleBufferGetFormatDescription(sample_buffer);
+  const AudioStreamBasicDescription* asbd =
+      CMAudioFormatDescriptionGetStreamBasicDescription(description);
+  if (!asbd) {
+    RTCLogError(@"External recorded data was not in audio format.");
+    return;
+  }
+
+  if (asbd->mSampleRate != record_parameters_.sample_rate() ||
+      asbd->mChannelsPerFrame != record_parameters_.channels()) {
+    record_parameters_.reset(asbd->mSampleRate, asbd->mChannelsPerFrame);
+    UpdateAudioDeviceBuffer();
+
+    // Create a modified audio buffer class which allows us to ask for,
+    // or deliver, any number of samples (and not only multiple of 10ms) to match
+    // the native audio unit buffer size.
+    RTC_DCHECK(audio_device_buffer_);
+    fine_audio_buffer_.reset(new FineAudioBuffer(audio_device_buffer_));
+  }
+
+  CMBlockBufferRef block_buffer = CMSampleBufferGetDataBuffer(sample_buffer);
+  if (block_buffer == nil) {
+    return;
+  }
+
+  AudioBufferList buffer_list;
+  CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer(
+      sample_buffer,
+      nullptr,
+      &buffer_list,
+      sizeof(buffer_list),
+      nullptr,
+      nullptr,
+      kCMSampleBufferFlag_AudioBufferList_Assure16ByteAlignment,
+      &block_buffer);
+
+  rtc::ArrayView<int16_t> view{static_cast<int16_t*>(buffer_list.mBuffers[0].mData),
+                               buffer_list.mBuffers[0].mDataByteSize / sizeof(int16_t)};
+
+  if (asbd->mFormatFlags & kAudioFormatFlagIsBigEndian) {
+    for (auto& element : view) {
+      element = be16toh(element);
+    }
+  }
+
+  fine_audio_buffer_->DeliverRecordedData(view, kFixedRecordDelayEstimate);
+
+  CFRelease(block_buffer);
+}
+
 OSStatus AudioDeviceIOS::OnDeliverRecordedData(AudioUnitRenderActionFlags* flags,
                                                const AudioTimeStamp* time_stamp,
                                                UInt32 bus_number,
                                                UInt32 num_frames,
                                                AudioBufferList* /* io_data */) {
-  RTC_DCHECK_RUN_ON(&io_thread_checker_);
+  // RTC_DCHECK_RUN_ON(&io_thread_checker_);
+  MutexLock scoped_lock(&io_mutex_);
   OSStatus result = noErr;
   // Simply return if recording is not enabled.
   if (!recording_.load(std::memory_order_acquire)) return result;
@@ -413,8 +472,9 @@ static void LogDeviceInfo() {
                                           UInt32 bus_number,
                                           UInt32 num_frames,
                                           AudioBufferList* io_data) {
-  RTC_DCHECK_RUN_ON(&io_thread_checker_);
-  // Verify 16-bit, noninterleaved mono PCM signal format.
+  // RTC_DCHECK_RUN_ON(&io_thread_checker_);
+  //  Verify 16-bit, noninterleaved mono PCM signal format.
+  MutexLock scoped_lock(&io_mutex_);
   RTC_DCHECK_EQ(1, io_data->mNumberBuffers);
   AudioBuffer* audio_buffer = &io_data->mBuffers[0];
   RTC_DCHECK_EQ(1, audio_buffer->mNumberChannels);
@@ -638,15 +698,26 @@ static void LogDeviceInfo() {
   // AttachAudioBuffer() is called at construction by the main class but check
   // just in case.
   RTC_DCHECK(audio_device_buffer_) << "AttachAudioBuffer must be called first";
-  RTC_DCHECK_GT(playout_parameters_.sample_rate(), 0);
-  RTC_DCHECK_GT(record_parameters_.sample_rate(), 0);
-  RTC_DCHECK_EQ(playout_parameters_.channels(), 1);
-  RTC_DCHECK_EQ(record_parameters_.channels(), 1);
-  // Inform the audio device buffer (ADB) about the new audio format.
-  audio_device_buffer_->SetPlayoutSampleRate(playout_parameters_.sample_rate());
-  audio_device_buffer_->SetPlayoutChannels(playout_parameters_.channels());
-  audio_device_buffer_->SetRecordingSampleRate(record_parameters_.sample_rate());
-  audio_device_buffer_->SetRecordingChannels(record_parameters_.channels());
+  // RTC_DCHECK_GT(playout_parameters_.sample_rate(), 0);
+  // RTC_DCHECK_GT(record_parameters_.sample_rate(), 0);
+  // RTC_DCHECK_EQ(playout_parameters_.channels(), 1);
+  // RTC_DCHECK_EQ(record_parameters_.channels(), 1);
+  //  Inform the audio device buffer (ADB) about the new audio format.
+  // audio_device_buffer_->SetPlayoutSampleRate(playout_parameters_.sample_rate());
+  // audio_device_buffer_->SetPlayoutChannels(playout_parameters_.channels());
+  // audio_device_buffer_->SetRecordingSampleRate(record_parameters_.sample_rate());
+  // audio_device_buffer_->SetRecordingChannels(record_parameters_.channels());
+
+  if (playout_parameters_.is_valid()) {
+    // RTC_DCHECK_EQ(playout_parameters_.channels(), 1);
+    audio_device_buffer_->SetPlayoutSampleRate(playout_parameters_.sample_rate());
+    audio_device_buffer_->SetPlayoutChannels(playout_parameters_.channels());
+  }
+  if (record_parameters_.is_valid()) {
+    // RTC_DCHECK_EQ(record_parameters_.channels(), 1);
+    audio_device_buffer_->SetRecordingSampleRate(record_parameters_.sample_rate());
+    audio_device_buffer_->SetRecordingChannels(record_parameters_.channels());
+  }
 }
 
 void AudioDeviceIOS::SetupAudioBuffersForActiveAudioSession() {
@@ -683,9 +754,13 @@ static void LogDeviceInfo() {
   // number of audio frames.
   // Example: IO buffer size = 0.008 seconds <=> 128 audio frames at 16kHz.
   // Hence, 128 is the size we expect to see in upcoming render callbacks.
-  playout_parameters_.reset(sample_rate, playout_parameters_.channels(), io_buffer_duration);
+  // playout_parameters_.reset(sample_rate, playout_parameters_.channels(), io_buffer_duration);
+  playout_parameters_.reset(sample_rate, webRTCConfig.outputNumberOfChannels, io_buffer_duration);
+
   RTC_DCHECK(playout_parameters_.is_complete());
-  record_parameters_.reset(sample_rate, record_parameters_.channels(), io_buffer_duration);
+  // record_parameters_.reset(sample_rate, record_parameters_.channels(), io_buffer_duration);
+  record_parameters_.reset(sample_rate, webRTCConfig.inputNumberOfChannels, io_buffer_duration);
+
   RTC_DCHECK(record_parameters_.is_complete());
   RTC_LOG(LS_INFO) << " frames per I/O buffer: " << playout_parameters_.frames_per_buffer();
   RTC_LOG(LS_INFO) << " bytes per I/O buffer: " << playout_parameters_.GetBytesPerBuffer();
@@ -729,7 +804,12 @@ static void LogDeviceInfo() {
   if (!audio_is_initialized_) return;
 
   // If we're initialized, we must have an audio unit.
-  RTC_DCHECK(audio_unit_);
+  // RTC_DCHECK(audio_unit_);
+
+  if (can_play_or_record && !audio_unit_ && !CreateAudioUnit()) {
+    RTCLog(@"Failed to create audio unit.");
+    return;
+  }
 
   bool should_initialize_audio_unit = false;
   bool should_uninitialize_audio_unit = false;
@@ -859,9 +939,9 @@ static void LogDeviceInfo() {
   RTC_DCHECK_RUN_ON(thread_);
 
   // There should be no audio unit at this point.
-  if (!CreateAudioUnit()) {
-    return false;
-  }
+  // if (!CreateAudioUnit()) {
+  //  return false;
+  //}
 
   RTC_OBJC_TYPE(RTCAudioSession)* session = [RTC_OBJC_TYPE(RTCAudioSession) sharedInstance];
   // Subscribe to audio session events.
@@ -881,6 +961,25 @@ static void LogDeviceInfo() {
   // If we are ready to play or record, and if the audio session can be
   // configured, then initialize the audio unit.
   if (session.canPlayOrRecord) {
+    // Store the preferred sample rate and preferred number of channels already
+    // here. They have not been set and confirmed yet since configureForWebRTC
+    // is not called until audio is about to start. However, it makes sense to
+    // store the parameters now and then verify at a later stage.
+    RTC_OBJC_TYPE(RTCAudioSessionConfiguration)* config =
+        [RTC_OBJC_TYPE(RTCAudioSessionConfiguration) webRTCConfiguration];
+    playout_parameters_.reset(config.sampleRate, config.outputNumberOfChannels);
+    record_parameters_.reset(config.sampleRate, config.inputNumberOfChannels);
+    // Ensure that the audio device buffer (ADB) knows about the internal audio
+    // parameters. Note that, even if we are unable to get a mono audio session,
+    // we will always tell the I/O audio unit to do a channel format conversion
+    // to guarantee mono on the "input side" of the audio unit.
+    UpdateAudioDeviceBuffer();
+
+    // There should be no audio unit at this point.
+    if (!CreateAudioUnit()) {
+      [session unlockForConfiguration];
+      return false;
+    }
     if (!ConfigureAudioSessionLocked()) {
       // One possible reason for failure is if an attempt was made to use the
       // audio session during or after a Media Services failure.
@@ -910,7 +1009,7 @@ static void LogDeviceInfo() {
 
   // Detach thread checker for the AURemoteIO::IOThread to ensure that the
   // next session uses a fresh thread id.
-  io_thread_checker_.Detach();
+  // io_thread_checker_.Detach();
 
   // Remove audio session notification observers.
   RTC_OBJC_TYPE(RTCAudioSession)* session = [RTC_OBJC_TYPE(RTCAudioSession) sharedInstance];
@@ -927,7 +1026,7 @@ static void LogDeviceInfo() {
   // restart. It will result in audio callbacks from a new native I/O thread
   // which means that we must detach thread checkers here to be prepared for an
   // upcoming new audio stream.
-  io_thread_checker_.Detach();
+  // io_thread_checker_.Detach();
 }
 
 bool AudioDeviceIOS::IsInterrupted() {
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.h b/sdk/objc/native/src/audio/audio_device_module_ios.h
index 189d7e6c9c..9e099a58e1 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.h
@@ -18,6 +18,9 @@
 #include "modules/audio_device/audio_device_buffer.h"
 #include "modules/audio_device/include/audio_device.h"
 #include "rtc_base/checks.h"
+#if defined(WEBRTC_IOS)
+#include <CoreMedia/CoreMedia.h>
+#endif
 
 namespace webrtc {
 
@@ -126,6 +129,7 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
   int32_t GetPlayoutUnderrunCount() const override;
 
 #if defined(WEBRTC_IOS)
+  void OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer);
   int GetPlayoutAudioParameters(AudioParameters* params) const override;
   int GetRecordAudioParameters(AudioParameters* params) const override;
 #endif  // WEBRTC_IOS
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.mm b/sdk/objc/native/src/audio/audio_device_module_ios.mm
index 5effef3abd..1753e0820d 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.mm
@@ -649,6 +649,11 @@
   }
 
 #if defined(WEBRTC_IOS)
+
+  void AudioDeviceModuleIOS::OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer) {
+    audio_device_->OnDeliverRecordedExternalData(sample_buffer);
+  }
+
   int AudioDeviceModuleIOS::GetPlayoutAudioParameters(
       AudioParameters* params) const {
     RTC_DLOG(LS_INFO) << __FUNCTION__;
diff --git a/sdk/objc/native/src/audio/voice_processing_audio_unit.mm b/sdk/objc/native/src/audio/voice_processing_audio_unit.mm
index 3905b6857a..665d790336 100644
--- a/sdk/objc/native/src/audio/voice_processing_audio_unit.mm
+++ b/sdk/objc/native/src/audio/voice_processing_audio_unit.mm
@@ -112,16 +112,25 @@ static OSStatus GetAGCState(AudioUnit audio_unit, UInt32* enabled) {
   }
 
   // Enable input on the input scope of the input element.
-  UInt32 enable_input = 1;
-  result = AudioUnitSetProperty(vpio_unit_, kAudioOutputUnitProperty_EnableIO,
-                                kAudioUnitScope_Input, kInputBus, &enable_input,
-                                sizeof(enable_input));
-  if (result != noErr) {
-    DisposeAudioUnit();
-    RTCLogError(@"Failed to enable input on input scope of input element. "
-                 "Error=%ld.",
-                (long)result);
-    return false;
+  RTCAudioSessionConfiguration* webRTCConfiguration =
+      [RTCAudioSessionConfiguration webRTCConfiguration];
+  if (webRTCConfiguration.mode != AVAudioSessionModeMoviePlayback) {
+    UInt32 enable_input = 1;
+    result = AudioUnitSetProperty(vpio_unit_,
+                                  kAudioOutputUnitProperty_EnableIO,
+                                  kAudioUnitScope_Input,
+                                  kInputBus,
+                                  &enable_input,
+                                  sizeof(enable_input));
+    if (result != noErr) {
+      DisposeAudioUnit();
+      RTCLogError(@"Failed to enable input on input scope of input element. "
+                   "Error=%ld.",
+                  (long)result);
+      return false;
+    }
+  } else {
+    RTCLog(@"Not Enable input on the input scope of the input element.");
   }
 
   // Enable output on the output scope of the output element.
@@ -155,34 +164,47 @@ static OSStatus GetAGCState(AudioUnit audio_unit, UInt32* enabled) {
 
   // Disable AU buffer allocation for the recorder, we allocate our own.
   // TODO(henrika): not sure that it actually saves resource to make this call.
-  UInt32 flag = 0;
-  result = AudioUnitSetProperty(
-      vpio_unit_, kAudioUnitProperty_ShouldAllocateBuffer,
-      kAudioUnitScope_Output, kInputBus, &flag, sizeof(flag));
-  if (result != noErr) {
-    DisposeAudioUnit();
-    RTCLogError(@"Failed to disable buffer allocation on the input bus. "
-                 "Error=%ld.",
-                (long)result);
-    return false;
+  if (webRTCConfiguration.mode != AVAudioSessionModeMoviePlayback) {
+    UInt32 flag = 0;
+    result = AudioUnitSetProperty(vpio_unit_,
+                                  kAudioUnitProperty_ShouldAllocateBuffer,
+                                  kAudioUnitScope_Output,
+                                  kInputBus,
+                                  &flag,
+                                  sizeof(flag));
+    if (result != noErr) {
+      DisposeAudioUnit();
+      RTCLogError(@"Failed to disable buffer allocation on the input bus. "
+                   "Error=%ld.",
+                  (long)result);
+      return false;
+    }
+  } else {
+    RTCLog(@"Webrtc mode is movie and it's not allocating buffer for the recorder ");
   }
 
   // Specify the callback to be called by the I/O thread to us when input audio
   // is available. The recorded samples can then be obtained by calling the
   // AudioUnitRender() method.
-  AURenderCallbackStruct input_callback;
-  input_callback.inputProc = OnDeliverRecordedData;
-  input_callback.inputProcRefCon = this;
-  result = AudioUnitSetProperty(vpio_unit_,
-                                kAudioOutputUnitProperty_SetInputCallback,
-                                kAudioUnitScope_Global, kInputBus,
-                                &input_callback, sizeof(input_callback));
-  if (result != noErr) {
-    DisposeAudioUnit();
-    RTCLogError(@"Failed to specify the input callback on the input bus. "
-                 "Error=%ld.",
-                (long)result);
-    return false;
+  if (webRTCConfiguration.mode != AVAudioSessionModeMoviePlayback) {
+    AURenderCallbackStruct input_callback;
+    input_callback.inputProc = OnDeliverRecordedData;
+    input_callback.inputProcRefCon = this;
+    result = AudioUnitSetProperty(vpio_unit_,
+                                  kAudioOutputUnitProperty_SetInputCallback,
+                                  kAudioUnitScope_Global,
+                                  kInputBus,
+                                  &input_callback,
+                                  sizeof(input_callback));
+    if (result != noErr) {
+      DisposeAudioUnit();
+      RTCLogError(@"Failed to specify the input callback on the input bus. "
+                   "Error=%ld.",
+                  (long)result);
+      return false;
+    }
+  } else {
+    RTCLog(@"WebRTC mode is movie and it's not arranging the callback");
   }
 
   state_ = kUninitialized;
@@ -205,14 +227,24 @@ static OSStatus GetAGCState(AudioUnit audio_unit, UInt32* enabled) {
 #endif
 
   // Set the format on the output scope of the input element/bus.
-  result =
-      AudioUnitSetProperty(vpio_unit_, kAudioUnitProperty_StreamFormat,
-                           kAudioUnitScope_Output, kInputBus, &format, size);
-  if (result != noErr) {
-    RTCLogError(@"Failed to set format on output scope of input bus. "
-                 "Error=%ld.",
-                (long)result);
-    return false;
+  RTCAudioSessionConfiguration* webRTCConfiguration =
+      [RTCAudioSessionConfiguration webRTCConfiguration];
+  if (webRTCConfiguration.mode != AVAudioSessionModeMoviePlayback) {
+    result = AudioUnitSetProperty(vpio_unit_,
+                                  kAudioUnitProperty_StreamFormat,
+                                  kAudioUnitScope_Output,
+                                  kInputBus,
+                                  &format,
+                                  size);
+    if (result != noErr) {
+      RTCLogError(@"Failed to set format on output scope of input bus. "
+                   "Error=%ld.",
+                  (long)result);
+      return false;
+    }
+  } else {
+    RTCLog(
+        @"NOT setting the format on the output scope of the input element because it's movie mode");
   }
 
   // Set the format on the input scope of the output element/bus.
-- 
2.39.3 (Apple Git-145)

From b8a74f487081b40cc8d0f38ce17e2288300fa212 Mon Sep 17 00:00:00 2001
From: mekya <ahmetmermerkaya@gmail.com>
Date: Sat, 26 Nov 2022 15:44:59 +0300
Subject: [PATCH 2/2] Enable/disable external audio for audio device

Signed-off-by: mekya <ahmetmermerkaya@gmail.com>
Signed-off-by: Antti Tapaninen <aet@aet.fi>
---
 .../api/peerconnection/RTCAudioDeviceModule.h  |  4 +++-
 .../api/peerconnection/RTCAudioDeviceModule.mm |  6 +++++-
 sdk/objc/native/src/audio/audio_device_ios.h   |  7 +++++++
 sdk/objc/native/src/audio/audio_device_ios.mm  | 13 +++++++++++--
 .../native/src/audio/audio_device_module_ios.h |  2 ++
 .../src/audio/audio_device_module_ios.mm       | 18 +++++++++++++++++-
 6 files changed, 45 insertions(+), 5 deletions(-)

diff --git a/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h
index d8aba54508..4eb89e4e77 100644
--- a/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h
+++ b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.h
@@ -13,6 +13,8 @@ NS_CLASS_AVAILABLE_IOS(2_0)
 
 - (void)deliverRecordedData:(CMSampleBufferRef)sampleBuffer;
 
+- (void)setExternalAudio:(bool)enable;
+
 @end
 
-NS_ASSUME_NONNULL_END
\ No newline at end of file
+NS_ASSUME_NONNULL_END
diff --git a/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm
index 531bac8eda..542aeb31cc 100644
--- a/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm
+++ b/sdk/objc/api/peerconnection/RTCAudioDeviceModule.mm
@@ -18,10 +18,14 @@ - (void)deliverRecordedData:(CMSampleBufferRef)sampleBuffer {
   _nativeModule->OnDeliverRecordedExternalData(sampleBuffer);
 }
 
+- (void)setExternalAudio:(bool)enabled {
+  _nativeModule->setExternalAudio(enabled);
+}
+
 #pragma mark - Private
 
 - (rtc::scoped_refptr<webrtc::ios_adm::AudioDeviceModuleIOS>)nativeModule {
   return _nativeModule;
 }
 
-@end
\ No newline at end of file
+@end
diff --git a/sdk/objc/native/src/audio/audio_device_ios.h b/sdk/objc/native/src/audio/audio_device_ios.h
index 615eec47ee..1aa42a4844 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_ios.h
@@ -158,6 +158,9 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
                                  UInt32 bus_number,
                                  UInt32 num_frames,
                                  AudioBufferList* io_data) override;
+
+  void setExternalAudio(bool enable);
+
   OSStatus OnGetPlayoutData(AudioUnitRenderActionFlags* flags,
                             const AudioTimeStamp* time_stamp,
                             UInt32 bus_number,
@@ -283,6 +286,10 @@ class AudioDeviceIOS : public AudioDeviceGeneric,
   // Set to true if audio session is interrupted, false otherwise.
   bool is_interrupted_;
 
+  // if it's true, it does not get recording and expect
+  // OnDeliverRecordedExternalData to be called
+  bool externalAudio_;
+
   // Audio interruption observer instance.
   RTCNativeAudioSessionDelegateAdapter* audio_session_observer_
       RTC_GUARDED_BY(thread_);
diff --git a/sdk/objc/native/src/audio/audio_device_ios.mm b/sdk/objc/native/src/audio/audio_device_ios.mm
index 2c551922c3..f91ad208e2 100644
--- a/sdk/objc/native/src/audio/audio_device_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_ios.mm
@@ -99,6 +99,7 @@ static void LogDeviceInfo() {
       initialized_(false),
       audio_is_initialized_(false),
       is_interrupted_(false),
+      externalAudio_(false),
       has_configured_session_(false),
       num_detected_playout_glitches_(0),
       last_playout_time_(0),
@@ -360,11 +361,15 @@ static void LogDeviceInfo() {
   thread_->PostTask(SafeTask(safety_, [this] { HandleOutputVolumeChange(); }));
 }
 
+void AudioDeviceIOS::setExternalAudio(bool enable) {
+  externalAudio_ = enable;
+}
+
 void AudioDeviceIOS::OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer) {
   MutexLock scoped_lock(&io_mutex_);
 
-  if (audio_unit_ && audio_unit_->GetState() != VoiceProcessingAudioUnit::kUninitialized) {
-    RTCLogError(@"External recorded data was provided while audio unit is enabled.");
+  if (!this->externalAudio_) {
+    RTCLogError(@"External audio is not enabled so discarding the incoming data");
     return;
   }
 
@@ -423,6 +428,10 @@ static void LogDeviceInfo() {
                                                UInt32 bus_number,
                                                UInt32 num_frames,
                                                AudioBufferList* /* io_data */) {
+  if (this->externalAudio_) {
+    RTCLogError(@"External Audio is enabled so not using current recorded audio");
+    return noErr;
+  }
   // RTC_DCHECK_RUN_ON(&io_thread_checker_);
   MutexLock scoped_lock(&io_mutex_);
   OSStatus result = noErr;
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.h b/sdk/objc/native/src/audio/audio_device_module_ios.h
index 9e099a58e1..663ca0a7fa 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.h
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.h
@@ -130,12 +130,14 @@ class AudioDeviceModuleIOS : public AudioDeviceModule {
 
 #if defined(WEBRTC_IOS)
   void OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer);
+  void setExternalAudio(bool enable);
   int GetPlayoutAudioParameters(AudioParameters* params) const override;
   int GetRecordAudioParameters(AudioParameters* params) const override;
 #endif  // WEBRTC_IOS
  private:
   const bool bypass_voice_processing_;
   bool initialized_ = false;
+  bool externalAudio_ = false;
   const std::unique_ptr<TaskQueueFactory> task_queue_factory_;
   std::unique_ptr<AudioDeviceIOS> audio_device_;
   std::unique_ptr<AudioDeviceBuffer> audio_device_buffer_;
diff --git a/sdk/objc/native/src/audio/audio_device_module_ios.mm b/sdk/objc/native/src/audio/audio_device_module_ios.mm
index 1753e0820d..30ee6cb0ad 100644
--- a/sdk/objc/native/src/audio/audio_device_module_ios.mm
+++ b/sdk/objc/native/src/audio/audio_device_module_ios.mm
@@ -73,6 +73,9 @@
 
     audio_device_buffer_.reset(new webrtc::AudioDeviceBuffer(task_queue_factory_.get()));
     audio_device_.reset(new ios_adm::AudioDeviceIOS(bypass_voice_processing_));
+
+    audio_device_->setExternalAudio(this->externalAudio_);
+
     RTC_CHECK(audio_device_);
 
     this->AttachAudioBuffer();
@@ -651,7 +654,20 @@
 #if defined(WEBRTC_IOS)
 
   void AudioDeviceModuleIOS::OnDeliverRecordedExternalData(CMSampleBufferRef sample_buffer) {
-    audio_device_->OnDeliverRecordedExternalData(sample_buffer);
+    if (audio_device_) {
+      audio_device_->OnDeliverRecordedExternalData(sample_buffer);
+    } else {
+      RTC_DLOG(LS_WARNING) << "audio device is not ready ";
+    }
+  }
+
+  void AudioDeviceModuleIOS::setExternalAudio(bool enable) {
+    this->externalAudio_ = enable;
+    if (audio_device_) {
+      audio_device_->setExternalAudio(enable);
+    } else {
+      RTC_DLOG(LS_INFO) << "audio device is not ready ";
+    }
   }
 
   int AudioDeviceModuleIOS::GetPlayoutAudioParameters(
-- 
2.39.3 (Apple Git-145)

